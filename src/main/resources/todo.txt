Local:
x- implement delete (we can say that value length of -2 means it's deleted. on compaction we can just eliminate that record entirely.)
- implement update (in-memory, latest value wins; from disk, value with latest file timestamp wins)
--> make sure ChainedIterables are sorted (merge sort style) when needed
- think about interaction between scans and updates/deletes. when we're picking off the front of multiple sources, we need to make sure we're taking the latest timestamp first. and then if we see that value after, we need to ignore it. so we should always be storing the most recent value read.
- make sure file index is persisted
- test basic persistence (restart)
- clean up conf
- decide whether we want non-flushed writes to be readable after shutdown. if yes:
--> log everything before writing it to memory (this can't be the actual data file because it won't be ordered)
--> clear log after flush to disk
--> shutdown/close should flush memstore
--> implement recovery using logs (i.e. on restart, if we have a log that hasn't been properly flushed yet, flush it to disk)
- compaction
- bloom filters
- add pools for getting tables
- figure out concurrency and thread safety!

 Distributed:
 - raft? need to do a bit more research (BigTable uses Paxos, so hopefully can do something similar)